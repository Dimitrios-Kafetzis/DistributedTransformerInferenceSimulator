# -*- coding: utf-8 -*-
#
# Copyright (c) 2024 Dimitrios Kafetzis
#
# This file is part of the Transformer Inference Simulator project.
# Licensed under the MIT License; you may not use this file except in compliance
# with the License. You may obtain a copy of the License at
#   https://opensource.org/licenses/MIT
#
# Author:  Dimitrios Kafetzis (dimitrioskafetzis@gmail.com)
# File:    experiments/configs/distributed_edge.yaml
# Description:
#   Specifies the network, resource, and workload configurations for a
#   distributed-edge scenario with multiple heterogeneous devices and
#   moderate bandwidth links for Transformer inference.
#
# ---------------------------------------------------------------------------

network:
  topology_type: "distributed_edge"
  num_devices: 16
  min_bandwidth: 0.1    # 100 Mbps
  max_bandwidth: 1.0    # 1 Gbps
  edge_probability: 0.3
  seed: 42

resources:
  # Log-normal distribution parameters for heterogeneous devices
  memory_mu: 2.0
  memory_sigma: 0.5
  memory_min: 4.0    # Minimum 4GB RAM
  memory_max: 32.0   # Maximum 32GB RAM
  compute_mu: 5.0
  compute_sigma: 0.5
  compute_min: 20.0e9  # Minimum 20 GFLOPS
  compute_max: 200.0e9 # Maximum 200 GFLOPS
  seed: 42

workload:
  model_type: "LARGE" 
  initial_sequence_lengths: [128, 256, 512]
  generation_steps: [32, 64, 128]
  precision_bytes: 4
  seed: 42

algorithm:
  migration_threshold: 0.9
  backtrack_limit: 100
  cache_placement_strategy: "colocated"
  enable_dynamic_adjustment: true

experiment:
  name: "distributed_edge_evaluation"
  description: "Distributed edge evaluation with 16 devices"
  num_runs: 10
  checkpoint_interval: 10
  time_limit: 7200  # 2 hours
  metrics_output_dir: "results/distributed_edge"
  save_intermediate: true